"""
Script ri√™ng bi·ªát ƒë·ªÉ x·ª≠ l√Ω:
1. Export Excel (.xlsx) sang CSV
2. Import CSV v√†o database SQLite

S·ª≠ d·ª•ng:
    # Export t·∫•t c·∫£ sheets ra CSV
    python excel_to_csv_import.py export path/to/file.xlsx --output-dir ./csv_output
    
    # Export ch·ªâ m·ªôt s·ªë sheets c·ª• th·ªÉ
    python excel_to_csv_import.py export path/to/file.xlsx --sheets san_pham kh_ncc --output-dir ./csv_output
    
    # Import t·ª´ CSV v√†o database
    python excel_to_csv_import.py import path/to/csv_folder --table product
    
    # Import t·∫•t c·∫£ CSV files trong folder
    python excel_to_csv_import.py import path/to/csv_folder --all
    
    # Pipeline: Export + Import c√πng l√∫c
    python excel_to_csv_import.py pipeline path/to/file.xlsx

Author: AI Assistant
Created: 2024
"""

from __future__ import annotations

import argparse
import csv
import sys
from pathlib import Path
from datetime import datetime, date
from typing import Any, Generator
import os

import pandas as pd

# Th√™m path ƒë·ªÉ import backend modules
sys.path.insert(0, str(Path(__file__).parent.parent))


# =============================================================================
# UTILITY FUNCTIONS
# =============================================================================

def safe_str(value: Any) -> str | None:
    """Chuy·ªÉn ƒë·ªïi gi√° tr·ªã sang string an to√†n."""
    if pd.isna(value) or value is None:
        return None
    result = str(value).strip()
    return result if result else None


def safe_float(value: Any) -> float | None:
    """Chuy·ªÉn ƒë·ªïi gi√° tr·ªã sang float an to√†n."""
    if pd.isna(value) or value is None:
        return None
    try:
        return float(value)
    except (ValueError, TypeError):
        return None


def safe_int(value: Any) -> int | None:
    """Chuy·ªÉn ƒë·ªïi gi√° tr·ªã sang int an to√†n."""
    if pd.isna(value) or value is None:
        return None
    try:
        return int(float(value))
    except (ValueError, TypeError):
        return None


def safe_date(value: Any) -> date | None:
    """Chuy·ªÉn ƒë·ªïi gi√° tr·ªã sang date an to√†n."""
    if pd.isna(value) or value is None:
        return None
    if isinstance(value, date):
        return value
    if isinstance(value, datetime):
        return value.date()
    try:
        if isinstance(value, str):
            for fmt in ["%Y-%m-%d", "%d/%m/%Y", "%m/%d/%Y", "%Y/%m/%d"]:
                try:
                    return datetime.strptime(value, fmt).date()
                except ValueError:
                    continue
        return pd.to_datetime(value).date()
    except (ValueError, TypeError):
        return None


def clean_column_name(name: str) -> str:
    """Chu·∫©n h√≥a t√™n c·ªôt: lowercase, thay space b·∫±ng underscore."""
    return str(name).strip().lower().replace(" ", "_").replace("-", "_")


# =============================================================================
# EXCEL TO CSV EXPORT
# =============================================================================

class ExcelToCsvExporter:
    """Class x·ª≠ l√Ω export Excel sang CSV."""
    
    def __init__(self, excel_path: str | Path, output_dir: str | Path = None):
        self.excel_path = Path(excel_path)
        self.output_dir = Path(output_dir) if output_dir else self.excel_path.parent / "csv_export"
        
        if not self.excel_path.exists():
            raise FileNotFoundError(f"File Excel kh√¥ng t·ªìn t·∫°i: {self.excel_path}")
    
    def get_sheet_names(self) -> list[str]:
        """L·∫•y danh s√°ch t√™n c√°c sheets trong file Excel."""
        xl = pd.ExcelFile(self.excel_path, engine='openpyxl')
        return xl.sheet_names
    
    def export_sheet(self, sheet_name: str, clean_columns: bool = True) -> Path:
        """
        Export m·ªôt sheet c·ª• th·ªÉ ra CSV.
        
        Args:
            sheet_name: T√™n sheet c·∫ßn export
            clean_columns: C√≥ chu·∫©n h√≥a t√™n c·ªôt kh√¥ng
            
        Returns:
            Path ƒë·∫øn file CSV ƒë√£ t·∫°o
        """
        try:
            df = pd.read_excel(self.excel_path, sheet_name=sheet_name, engine='openpyxl')
        except ValueError as e:
            raise ValueError(f"Sheet '{sheet_name}' kh√¥ng t·ªìn t·∫°i trong file Excel") from e
        
        # Chu·∫©n h√≥a t√™n c·ªôt n·∫øu c·∫ßn
        if clean_columns:
            df.columns = [clean_column_name(col) for col in df.columns]
        
        # T·∫°o th∆∞ m·ª•c output n·∫øu ch∆∞a c√≥
        self.output_dir.mkdir(parents=True, exist_ok=True)
        
        # T·∫°o file CSV
        csv_filename = f"{sheet_name}.csv"
        csv_path = self.output_dir / csv_filename
        
        # Export v·ªõi encoding UTF-8 BOM ƒë·ªÉ Excel ƒë·ªçc ƒë∆∞·ª£c ti·∫øng Vi·ªát
        df.to_csv(csv_path, index=False, encoding='utf-8-sig')
        
        print(f"‚úÖ ƒê√£ export sheet '{sheet_name}' -> {csv_path} ({len(df)} d√≤ng)")
        return csv_path
    
    def export_all(self, sheets: list[str] = None, clean_columns: bool = True) -> list[Path]:
        """
        Export nhi·ªÅu sheets ho·∫∑c t·∫•t c·∫£ sheets ra CSV.
        
        Args:
            sheets: Danh s√°ch sheets c·∫ßn export (None = t·∫•t c·∫£)
            clean_columns: C√≥ chu·∫©n h√≥a t√™n c·ªôt kh√¥ng
            
        Returns:
            Danh s√°ch paths ƒë·∫øn c√°c files CSV ƒë√£ t·∫°o
        """
        if sheets is None:
            sheets = self.get_sheet_names()
        
        print(f"\nüìÅ Export Excel sang CSV")
        print(f"   File ngu·ªìn: {self.excel_path}")
        print(f"   Th∆∞ m·ª•c ƒë√≠ch: {self.output_dir}")
        print(f"   S·ªë sheets: {len(sheets)}\n")
        
        exported = []
        for sheet_name in sheets:
            try:
                csv_path = self.export_sheet(sheet_name, clean_columns)
                exported.append(csv_path)
            except Exception as e:
                print(f"‚ö†Ô∏è  L·ªói export sheet '{sheet_name}': {e}")
        
        print(f"\n‚úÖ Ho√†n th√†nh! ƒê√£ export {len(exported)}/{len(sheets)} sheets")
        return exported


# =============================================================================
# CSV TO DATABASE IMPORT  
# =============================================================================

class CsvToDbImporter:
    """Class x·ª≠ l√Ω import CSV v√†o database."""
    
    # Mapping t·ª´ t√™n sheet/file CSV sang table name v√† model class
    TABLE_MAPPING = {
        "san_pham": ("product", "Product"),
        "khach_hang": ("customer", "Customer"),
        "kh_ncc": ("customer_supplier", None),  # C·∫ßn x·ª≠ l√Ω ri√™ng
        "nha_cung_cap": ("supplier", "Supplier"),
        "dm_kho": ("warehouse", "Warehouse"),
        "dskho": ("warehouse", "Warehouse"),
        "phong_ban": ("department", "Department"),
        "chuc_danh": ("jobtitle", "JobTitle"),
        "nhan_su": ("employee", "Employee"),
        "nhan_vien": ("employee", "Employee"),
        "don_hang": ("salesorder", "SalesOrder"),
        "lenh_sx": ("productionorder", "ProductionOrder"),
        "phieu_nx": ("stockdocument", "StockDocument"),
        "bom_sp": ("bommaterial", "BomMaterial"),
    }
    
    def __init__(self, csv_dir: str | Path = None):
        self.csv_dir = Path(csv_dir) if csv_dir else None
        self._db_session = None
    
    def _get_db_session(self):
        """Lazy load database session."""
        if self._db_session is None:
            from backend.app.core.db import SessionLocal
            self._db_session = SessionLocal()
        return self._db_session
    
    def _close_db_session(self):
        """ƒê√≥ng database session."""
        if self._db_session:
            self._db_session.close()
            self._db_session = None
    
    def _new_db_session(self):
        """T·∫°o session m·ªõi (khi session c≈© b·ªã l·ªói)."""
        self._close_db_session()
        return self._get_db_session()
    
    def load_csv(self, csv_path: Path) -> Generator[dict[str, str], None, None]:
        """ƒê·ªçc file CSV v√† yield t·ª´ng d√≤ng d∆∞·ªõi d·∫°ng dict."""
        with csv_path.open("r", encoding="utf-8-sig", newline="") as f:
            reader = csv.DictReader(f)
            for row in reader:
                yield row
    
    def import_products(self, csv_path: Path) -> int:
        """Import s·∫£n ph·∫©m t·ª´ CSV."""
        from backend.app.models.entities import Product
        from sqlalchemy.exc import IntegrityError
        
        db = self._get_db_session()
        count = 0
        skipped = 0
        duplicates = 0
        seen_codes = set()  # Track codes trong batch hi·ªán t·∫°i
        
        for row in self.load_csv(csv_path):
            # Map columns - h·ªó tr·ª£ nhi·ªÅu t√™n c·ªôt
            code = safe_str(row.get("id") or row.get("ma_sp") or row.get("code"))
            name = safe_str(row.get("ten_sp") or row.get("name"))
            group = safe_str(row.get("loai") or row.get("nhom_cap_1") or row.get("group"))
            main_uom = safe_str(row.get("dvt") or row.get("dvt_chinh") or row.get("main_uom")) or "kg"
            
            if not code or not name or not group:
                skipped += 1
                continue
            
            # Ki·ªÉm tra duplicate trong batch hi·ªán t·∫°i
            if code in seen_codes:
                duplicates += 1
                continue
            seen_codes.add(code)
            
            # Ki·ªÉm tra duplicate trong database
            existing = db.query(Product).filter_by(code=code).first()
            if existing:
                duplicates += 1
                continue
            
            product = Product(
                code=code,
                name=name,
                group=group,
                main_uom=main_uom,
                specification=safe_str(row.get("quy_cach") or row.get("specification")),
                secondary_uom=safe_str(row.get("dvt_quy_doi") or row.get("secondary_uom")),
                conversion_rate=safe_float(row.get("ty_le_quy_doi") or row.get("conversion_rate")),
                shelf_life_days=safe_int(row.get("hsd_ngay") or row.get("shelf_life_days")),
                cost_price=safe_float(row.get("gia_von") or row.get("cost_price")),
            )
            db.add(product)
            count += 1
            
            # Commit theo batch ƒë·ªÉ tr√°nh l·ªói memory
            if count % 100 == 0:
                try:
                    db.commit()
                except IntegrityError:
                    db.rollback()
                    print(f"   ‚ö†Ô∏è  L·ªói duplicate trong batch, rollback...")
        
        try:
            db.commit()
        except IntegrityError:
            db.rollback()
            print(f"   ‚ö†Ô∏è  L·ªói duplicate khi commit cu·ªëi, rollback...")
        
        print(f"‚úÖ Import products: {count} th√™m m·ªõi, {skipped} b·ªè qua, {duplicates} tr√πng l·∫∑p")
        return count
    
    def import_customers(self, csv_path: Path) -> int:
        """Import kh√°ch h√†ng t·ª´ CSV."""
        from backend.app.models.entities import Customer
        from sqlalchemy.exc import IntegrityError
        
        db = self._get_db_session()
        count = 0
        skipped = 0
        duplicates = 0
        seen_codes = set()
        
        for row in self.load_csv(csv_path):
            # L·ªçc ch·ªâ kh√°ch h√†ng (n·∫øu file kh_ncc)
            loai = safe_str(row.get("loai") or "")
            if loai:
                loai_lower = loai.lower()
                if not any(kw in loai_lower for kw in ["kh√°ch", "khach", "customer"]):
                    continue
            
            code = safe_str(row.get("id") or row.get("ma_kh") or row.get("code"))
            name = safe_str(row.get("ten_day_du") or row.get("ten_kh") or row.get("name"))
            level = safe_str(row.get("level") or row.get("cap_khach_hang")) or "Khac"
            channel = safe_str(row.get("kenh_npp") or row.get("kenh_ban") or row.get("channel")) or "Khac"
            
            if not code or not name:
                skipped += 1
                continue
            
            if code in seen_codes:
                duplicates += 1
                continue
            seen_codes.add(code)
            
            existing = db.query(Customer).filter_by(code=code).first()
            if existing:
                duplicates += 1
                continue
            
            customer = Customer(
                code=code,
                name=name,
                level=level,
                channel=channel,
                phone=safe_str(row.get("di_dong") or row.get("sdt") or row.get("phone")),
                email=safe_str(row.get("email")),
                address=safe_str(row.get("dia_chi") or row.get("address")),
                credit_limit=safe_float(row.get("cong_no_toi_da") or row.get("credit_limit")),
            )
            db.add(customer)
            count += 1
        
        try:
            db.commit()
        except IntegrityError:
            db.rollback()
        print(f"‚úÖ Import customers: {count} th√™m m·ªõi, {skipped} b·ªè qua, {duplicates} tr√πng l·∫∑p")
        return count
    
    def import_suppliers(self, csv_path: Path) -> int:
        """Import nh√† cung c·∫•p t·ª´ CSV."""
        from backend.app.models.entities import Supplier
        from sqlalchemy.exc import IntegrityError
        
        db = self._get_db_session()
        count = 0
        skipped = 0
        duplicates = 0
        seen_codes = set()
        
        for row in self.load_csv(csv_path):
            # L·ªçc ch·ªâ nh√† cung c·∫•p (n·∫øu file kh_ncc)
            loai = safe_str(row.get("loai") or "")
            if loai:
                loai_lower = loai.lower()
                if not any(kw in loai_lower for kw in ["nh√† cung c·∫•p", "nha cung cap", "ncc", "supplier"]):
                    continue
            
            code = safe_str(row.get("id") or row.get("ma_ncc") or row.get("code"))
            name = safe_str(row.get("ten_day_du") or row.get("ten_ncc") or row.get("name"))
            
            if not code or not name:
                skipped += 1
                continue
            
            if code in seen_codes:
                duplicates += 1
                continue
            seen_codes.add(code)
            
            existing = db.query(Supplier).filter_by(code=code).first()
            if existing:
                duplicates += 1
                continue
            
            supplier = Supplier(
                code=code,
                name=name,
                phone=safe_str(row.get("di_dong") or row.get("sdt") or row.get("phone")),
                email=safe_str(row.get("email")),
                address=safe_str(row.get("dia_chi") or row.get("address")),
                rating=safe_float(row.get("danh_gia") or row.get("rating")),
            )
            db.add(supplier)
            count += 1
        
        try:
            db.commit()
        except IntegrityError:
            db.rollback()
        print(f"‚úÖ Import suppliers: {count} th√™m m·ªõi, {skipped} b·ªè qua, {duplicates} tr√πng l·∫∑p")
        return count
    
    def import_warehouses(self, csv_path: Path) -> int:
        """Import kho t·ª´ CSV."""
        from backend.app.models.entities import Warehouse
        from sqlalchemy.exc import IntegrityError
        
        db = self._get_db_session()
        count = 0
        skipped = 0
        duplicates = 0
        seen_codes = set()
        
        for row in self.load_csv(csv_path):
            code = safe_str(row.get("id") or row.get("ma_kho") or row.get("code"))
            name = safe_str(row.get("ten_kho") or row.get("name"))
            wh_type = safe_str(row.get("loai_kho") or row.get("type")) or "Khac"
            
            if not code or not name:
                skipped += 1
                continue
            
            if code in seen_codes:
                duplicates += 1
                continue
            seen_codes.add(code)
            
            existing = db.query(Warehouse).filter_by(code=code).first()
            if existing:
                duplicates += 1
                continue
            
            warehouse = Warehouse(
                code=code,
                name=name,
                type=wh_type,
                location=safe_str(row.get("vi_tri") or row.get("location")),
            )
            db.add(warehouse)
            count += 1
        
        try:
            db.commit()
        except IntegrityError:
            db.rollback()
        print(f"‚úÖ Import warehouses: {count} th√™m m·ªõi, {skipped} b·ªè qua, {duplicates} tr√πng l·∫∑p")
        return count
    
    def import_departments(self, csv_path: Path) -> int:
        """Import ph√≤ng ban t·ª´ CSV."""
        from backend.app.models.entities import Department
        from sqlalchemy.exc import IntegrityError
        
        db = self._get_db_session()
        count = 0
        skipped = 0
        duplicates = 0
        seen_codes = set()
        
        for row in self.load_csv(csv_path):
            code = safe_str(row.get("id") or row.get("ma_pb") or row.get("code"))
            name = safe_str(row.get("ten_phong_ban") or row.get("ten_pb") or row.get("name"))
            
            if not code or not name:
                skipped += 1
                continue
            
            if code in seen_codes:
                duplicates += 1
                continue
            seen_codes.add(code)
            
            existing = db.query(Department).filter_by(code=code).first()
            if existing:
                duplicates += 1
                continue
            
            department = Department(
                code=code,
                name=name,
            )
            db.add(department)
            count += 1
        
        try:
            db.commit()
        except IntegrityError:
            db.rollback()
        print(f"‚úÖ Import departments: {count} th√™m m·ªõi, {skipped} b·ªè qua, {duplicates} tr√πng l·∫∑p")
        return count
    
    def import_employees(self, csv_path: Path) -> int:
        """Import nh√¢n vi√™n t·ª´ CSV."""
        from backend.app.models.entities import Employee
        from sqlalchemy.exc import IntegrityError
        
        db = self._get_db_session()
        count = 0
        skipped = 0
        duplicates = 0
        seen_codes = set()
        
        for row in self.load_csv(csv_path):
            code = safe_str(row.get("id") or row.get("ma_nv") or row.get("code"))
            name = safe_str(row.get("ho_ten") or row.get("ten_nv") or row.get("name"))
            
            if not code or not name:
                skipped += 1
                continue
            
            if code in seen_codes:
                duplicates += 1
                continue
            seen_codes.add(code)
            
            existing = db.query(Employee).filter_by(code=code).first()
            if existing:
                duplicates += 1
                continue
            
            employee = Employee(
                code=code,
                name=name,
                department_code=safe_str(row.get("phong_ban_id") or row.get("ma_pb")),
                jobtitle_code=safe_str(row.get("chuc_danh_id") or row.get("ma_cd")),
                phone=safe_str(row.get("dien_thoai") or row.get("sdt") or row.get("phone")),
                email=safe_str(row.get("email")),
                hire_date=safe_date(row.get("ngay_vao_lam") or row.get("hire_date")),
            )
            db.add(employee)
            count += 1
        
        try:
            db.commit()
        except IntegrityError:
            db.rollback()
        print(f"‚úÖ Import employees: {count} th√™m m·ªõi, {skipped} b·ªè qua, {duplicates} tr√πng l·∫∑p")
        return count
    
    def import_from_csv(self, csv_path: Path, table_type: str = None) -> int:
        """
        Import data t·ª´ m·ªôt file CSV.
        
        Args:
            csv_path: Path ƒë·∫øn file CSV
            table_type: Lo·∫°i b·∫£ng (product, customer, supplier, warehouse, department, employee)
                       N·∫øu None, s·∫Ω t·ª± ƒë·ªông detect t·ª´ t√™n file
        """
        csv_path = Path(csv_path)
        if not csv_path.exists():
            raise FileNotFoundError(f"File CSV kh√¥ng t·ªìn t·∫°i: {csv_path}")
        
        # Auto-detect table type t·ª´ t√™n file
        if table_type is None:
            file_stem = csv_path.stem.lower()
            if file_stem in self.TABLE_MAPPING:
                table_type = self.TABLE_MAPPING[file_stem][0]
            else:
                # Th·ª≠ match m·ªôt ph·∫ßn
                for key, (tbl, _) in self.TABLE_MAPPING.items():
                    if key in file_stem or file_stem in key:
                        table_type = tbl
                        break
        
        if table_type is None:
            print(f"‚ö†Ô∏è  Kh√¥ng x√°c ƒë·ªãnh ƒë∆∞·ª£c lo·∫°i b·∫£ng cho file: {csv_path.name}")
            return 0
        
        # X·ª≠ l√Ω ƒë·∫∑c bi·ªát cho file kh_ncc: import c·∫£ customer v√† supplier
        if table_type == "customer_supplier":
            print(f"\nüìÑ Import {csv_path.name} -> customer + supplier")
            count_cust = self.import_customers(csv_path)
            self._new_db_session()  # T·∫°o session m·ªõi
            count_supp = self.import_suppliers(csv_path)
            return count_cust + count_supp
        
        print(f"\nüìÑ Import {csv_path.name} -> {table_type}")
        
        # Map table type to import function
        import_funcs = {
            "product": self.import_products,
            "customer": self.import_customers,
            "supplier": self.import_suppliers,
            "warehouse": self.import_warehouses,
            "department": self.import_departments,
            "employee": self.import_employees,
        }
        
        import_func = import_funcs.get(table_type)
        if import_func is None:
            print(f"‚ö†Ô∏è  Ch∆∞a h·ªó tr·ª£ import b·∫£ng: {table_type}")
            return 0
        
        return import_func(csv_path)
    
    def import_all(self, csv_dir: Path = None) -> dict[str, int]:
        """
        Import t·∫•t c·∫£ files CSV trong th∆∞ m·ª•c.
        
        Returns:
            Dict mapping filename -> s·ªë records ƒë√£ import
        """
        csv_dir = Path(csv_dir) if csv_dir else self.csv_dir
        if csv_dir is None:
            raise ValueError("Ch∆∞a ch·ªâ ƒë·ªãnh th∆∞ m·ª•c CSV")
        
        if not csv_dir.exists():
            raise FileNotFoundError(f"Th∆∞ m·ª•c kh√¥ng t·ªìn t·∫°i: {csv_dir}")
        
        print(f"\nüìÅ Import t·∫•t c·∫£ CSV t·ª´: {csv_dir}")
        
        results = {}
        csv_files = list(csv_dir.glob("*.csv"))
        
        if not csv_files:
            print("‚ö†Ô∏è  Kh√¥ng t√¨m th·∫•y file CSV n√†o!")
            return results
        
        print(f"   T√¨m th·∫•y {len(csv_files)} files CSV\n")
        
        # Th·ª© t·ª± import ƒë·ªÉ ƒë·∫£m b·∫£o foreign key
        priority_order = [
            "department", "jobtitle", "warehouse", 
            "product", "customer", "supplier", "employee"
        ]
        
        # S·∫Øp x·∫øp files theo priority
        def get_priority(path: Path) -> int:
            stem = path.stem.lower()
            for key, (tbl, _) in self.TABLE_MAPPING.items():
                if key in stem or stem in key:
                    try:
                        return priority_order.index(tbl)
                    except ValueError:
                        return 100
            return 100
        
        csv_files.sort(key=get_priority)
        
        for csv_file in csv_files:
            try:
                # T·∫°o session m·ªõi cho m·ªói file ƒë·ªÉ tr√°nh l·ªói session
                self._new_db_session()
                count = self.import_from_csv(csv_file)
                results[csv_file.name] = count
            except Exception as e:
                print(f"‚ö†Ô∏è  L·ªói import {csv_file.name}: {e}")
                results[csv_file.name] = 0
        
        self._close_db_session()
        
        print(f"\n" + "="*50)
        print("üìä K·∫øt qu·∫£ import:")
        total = 0
        for fname, cnt in results.items():
            print(f"   {fname}: {cnt} records")
            total += cnt
        print(f"   T·ªîNG: {total} records")
        
        return results


# =============================================================================
# PIPELINE: EXPORT + IMPORT
# =============================================================================

def run_pipeline(excel_path: str, output_dir: str = None, sheets: list[str] = None):
    """
    Ch·∫°y pipeline ho√†n ch·ªânh: Export Excel -> CSV -> Import DB.
    
    Args:
        excel_path: ƒê∆∞·ªùng d·∫´n ƒë·∫øn file Excel
        output_dir: Th∆∞ m·ª•c ch·ª©a CSV (t·∫°m)
        sheets: Danh s√°ch sheets c·∫ßn x·ª≠ l√Ω (None = t·∫•t c·∫£)
    """
    excel_path = Path(excel_path)
    if output_dir is None:
        output_dir = excel_path.parent / "csv_temp"
    output_dir = Path(output_dir)
    
    print("="*60)
    print("üöÄ PIPELINE: Excel -> CSV -> Database")
    print("="*60)
    
    # Step 1: Export Excel to CSV
    print("\nüìå B∆Ø·ªöC 1: Export Excel sang CSV")
    exporter = ExcelToCsvExporter(excel_path, output_dir)
    exported_files = exporter.export_all(sheets=sheets)
    
    if not exported_files:
        print("‚ùå Kh√¥ng c√≥ file n√†o ƒë∆∞·ª£c export, d·ª´ng pipeline.")
        return
    
    # Step 2: Import CSV to Database
    print("\nüìå B∆Ø·ªöC 2: Import CSV v√†o Database")
    importer = CsvToDbImporter(output_dir)
    results = importer.import_all()
    
    print("\n" + "="*60)
    print("‚úÖ PIPELINE HO√ÄN TH√ÄNH!")
    print("="*60)
    
    return results


# =============================================================================
# CLI INTERFACE
# =============================================================================

def main():
    parser = argparse.ArgumentParser(
        description="Export Excel sang CSV v√† Import v√†o Database",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
V√≠ d·ª• s·ª≠ d·ª•ng:
  # Export t·∫•t c·∫£ sheets ra CSV
  python excel_to_csv_import.py export data/home.xlsx --output-dir ./csv_output
  
  # Export ch·ªâ m·ªôt s·ªë sheets
  python excel_to_csv_import.py export data/home.xlsx --sheets san_pham kh_ncc
  
  # Import t·ª´ th∆∞ m·ª•c CSV
  python excel_to_csv_import.py import ./csv_output --all
  
  # Import m·ªôt file CSV c·ª• th·ªÉ
  python excel_to_csv_import.py import ./csv_output/san_pham.csv --table product
  
  # Pipeline ho√†n ch·ªânh (export + import)
  python excel_to_csv_import.py pipeline data/home.xlsx
        """
    )
    
    subparsers = parser.add_subparsers(dest="command", help="L·ªánh c·∫ßn th·ª±c thi")
    
    # Export command
    export_parser = subparsers.add_parser("export", help="Export Excel sang CSV")
    export_parser.add_argument("excel_path", help="ƒê∆∞·ªùng d·∫´n file Excel (.xlsx)")
    export_parser.add_argument("--output-dir", "-o", help="Th∆∞ m·ª•c output cho CSV")
    export_parser.add_argument("--sheets", "-s", nargs="+", help="Danh s√°ch sheets c·∫ßn export")
    export_parser.add_argument("--list-sheets", "-l", action="store_true", help="Li·ªát k√™ t√™n c√°c sheets")
    
    # Import command  
    import_parser = subparsers.add_parser("import", help="Import CSV v√†o Database")
    import_parser.add_argument("path", help="ƒê∆∞·ªùng d·∫´n file CSV ho·∫∑c th∆∞ m·ª•c ch·ª©a CSV")
    import_parser.add_argument("--table", "-t", help="Lo·∫°i b·∫£ng (product, customer, supplier, etc.)")
    import_parser.add_argument("--all", "-a", action="store_true", help="Import t·∫•t c·∫£ CSV trong th∆∞ m·ª•c")
    
    # Pipeline command
    pipeline_parser = subparsers.add_parser("pipeline", help="Export Excel + Import Database")
    pipeline_parser.add_argument("excel_path", help="ƒê∆∞·ªùng d·∫´n file Excel (.xlsx)")
    pipeline_parser.add_argument("--output-dir", "-o", help="Th∆∞ m·ª•c t·∫°m cho CSV")
    pipeline_parser.add_argument("--sheets", "-s", nargs="+", help="Danh s√°ch sheets c·∫ßn x·ª≠ l√Ω")
    
    args = parser.parse_args()
    
    if args.command is None:
        parser.print_help()
        return
    
    if args.command == "export":
        exporter = ExcelToCsvExporter(args.excel_path, args.output_dir)
        
        if args.list_sheets:
            sheets = exporter.get_sheet_names()
            print("üìã Danh s√°ch sheets:")
            for i, name in enumerate(sheets, 1):
                print(f"   {i}. {name}")
            return
        
        exporter.export_all(sheets=args.sheets)
    
    elif args.command == "import":
        path = Path(args.path)
        importer = CsvToDbImporter()
        
        if path.is_dir() or args.all:
            importer.csv_dir = path if path.is_dir() else path.parent
            importer.import_all()
        else:
            importer.import_from_csv(path, args.table)
    
    elif args.command == "pipeline":
        run_pipeline(args.excel_path, args.output_dir, args.sheets)


if __name__ == "__main__":
    main()
